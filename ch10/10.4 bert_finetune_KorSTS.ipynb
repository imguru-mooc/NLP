{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d3f314173f4fbd976fc16a27da68b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=995526.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\",\n",
    "                                          cache_dir='bert_ckpt',\n",
    "                                          do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# BASE PARAM\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN = 28 * 2 \n",
    "\n",
    "DATA_IN_PATH = 'data_in/KOR'\n",
    "DATA_OUT_PATH = \"data_out/KOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'] \n",
      " [100, 102, 0, 101, 103]\n",
      "[101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 102]\n",
      "[101, 31178, 11356, 102]\n",
      "[CLS] 안녕하세요, 반갑습니다 [SEP]\n",
      "[CLS] Hello world [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Special Tokens\n",
    "print(tokenizer.all_special_tokens, \"\\n\", tokenizer.all_special_ids)\n",
    "\n",
    "# Test Tokenizers\n",
    "kor_encode = tokenizer.encode(\"안녕하세요, 반갑습니다\")\n",
    "eng_encode = tokenizer.encode(\"Hello world\")\n",
    "\n",
    "kor_decode = tokenizer.decode(kor_encode)\n",
    "eng_decode = tokenizer.decode(eng_encode)\n",
    "\n",
    "print(kor_encode)\n",
    "print(eng_encode)\n",
    "print(kor_decode)\n",
    "print(eng_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KorSTS Dataset\n",
    "\n",
    "Data from Kakaobrain:  https://github.com/kakaobrain/KorNLUDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # dataset: train - 5749, dev - 1500\n"
     ]
    }
   ],
   "source": [
    "# Load Train dataset\n",
    "\n",
    "TRAIN_STS_DF = os.path.join(DATA_IN_PATH, 'KorSTS', 'sts-train.tsv')\n",
    "DEV_STS_DF = os.path.join(DATA_IN_PATH, 'KorSTS', 'sts-dev.tsv')\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_STS_DF, header=0, delimiter = '\\t', quoting = 3)\n",
    "dev_data = pd.read_csv(DEV_STS_DF, header=0, delimiter = '\\t', quoting = 3)\n",
    "\n",
    "print(\"Total # dataset: train - {}, dev - {}\".format(len(train_data), len(dev_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Tokenizer\n",
    "\n",
    "# 참조: https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus\n",
    "\n",
    "def bert_tokenizer_v2(sent1, sent2, MAX_LEN):\n",
    "    \n",
    "    # For Two setenece input\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent1,\n",
    "        text_pair = sent2,\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True   # Construct attn. masks.\n",
    "        \n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask'] # And its attention mask (simply differentiates padding from non-padding).\n",
    "    token_type_id = encoded_dict['token_type_ids'] # differentiate two sentences\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\jikim\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2149: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def clean_text(sent):\n",
    "    sent_clean = re.sub(\"[^a-zA-Z0-9ㄱ-ㅣ가-힣\\\\s]\", \" \", sent)\n",
    "    return sent_clean\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "data_labels = []\n",
    "\n",
    "\n",
    "for sent1, sent2, score in train_data[['sentence1', 'sentence2', 'score']].values:\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer_v2(clean_text(sent1), clean_text(sent2), MAX_LEN)\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(score)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(sent1, sent2)\n",
    "        pass\n",
    "    \n",
    "train_input_ids = np.array(input_ids, dtype=int)\n",
    "train_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_inputs = (train_input_ids, train_attention_masks, train_type_ids)\n",
    "train_data_labels = np.array(data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV SET Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "data_labels = []\n",
    "\n",
    "for sent1, sent2, score in dev_data[['sentence1', 'sentence2', 'score']].values:\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer_v2(clean_text(sent1), clean_text(sent2), MAX_LEN)\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(score)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(sent1, sent2)\n",
    "        pass\n",
    "    \n",
    "dev_input_ids = np.array(input_ids, dtype=int)\n",
    "dev_attention_masks = np.array(attention_masks, dtype=int)\n",
    "dev_type_ids = np.array(token_type_ids, dtype=int)\n",
    "dev_inputs = (dev_input_ids, dev_attention_masks, dev_type_ids)\n",
    "dev_data_labels = np.array(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train labels: 5749, #dev labels: 1500\n"
     ]
    }
   ],
   "source": [
    "print(\"# train labels: {}, #dev labels: {}\".format(len(train_data_labels), len(dev_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertRegressor(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertRegressor, self).__init__()\n",
    "        \n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.num_class = num_class\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.regressor = tf.keras.layers.Dense(self.num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n",
    "                                                name=\"regressor\")\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        \n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.regressor(pooled_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "regression_model = TFBertRegressor(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PearsonCorrelationMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"pearson_correlation\", **kwargs):\n",
    "        super(PearsonCorrelationMetric, self).__init__(name=name, **kwargs)\n",
    "        self.y_true_list = []\n",
    "        self.y_pred_list = []\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, shape=[-1])\n",
    "        y_pred = tf.reshape(y_pred, shape=[-1])\n",
    "        self.y_true_list.append(y_true)\n",
    "        self.y_pred_list.append(y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        y_true = tf.concat(self.y_true_list, -1)\n",
    "        y_pred = tf.concat(self.y_pred_list, -1)\n",
    "        pearson_correlation = self.pearson(y_true, y_pred)\n",
    "        \n",
    "        return pearson_correlation\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.y_true_list = []\n",
    "        self.y_pred_list = []\n",
    "        \n",
    "\n",
    "    def pearson(self, true, pred):\n",
    "        m_true = tf.reduce_mean(true)\n",
    "        m_pred = tf.reduce_mean(pred)\n",
    "        m_true, m_pred = true-m_true, pred-m_pred\n",
    "        num = tf.reduce_sum(tf.multiply(m_true, m_pred))\n",
    "        den = tf.sqrt(tf.multiply(tf.reduce_sum(tf.square(m_true)), tf.reduce_sum(tf.square(m_pred)))) + 1e-12\n",
    "        return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metric = PearsonCorrelationMetric()\n",
    "regression_model.compile(optimizer=optimizer, loss=loss, metrics=[metric], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#학습 진행하기\n",
    "model_name = \"tf2_BERT_KorSTS\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_pearson_correlation', min_delta=0.0001,patience=2,mode='max')\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_pearson_correlation', verbose=1, save_best_only=True, save_weights_only=True,mode='max')\n",
    "\n",
    "# 학습과 eval 시작\n",
    "history = regression_model.fit(train_inputs, train_data_labels, epochs=NUM_EPOCHS,\n",
    "            validation_data = (dev_inputs, dev_data_labels),\n",
    "            batch_size=BATCH_SIZE, callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "#steps_for_epoch\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.load_weights(\"./data_out/KOR/tf2_BERT_KorSTS/weights_STS.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regression_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-56634de22b6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pearson_correlation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-88e1bab779b7>\u001b[0m in \u001b[0;36mplot_graphs\u001b[1;34m(history, string)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 시각화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "plot_graphs(history, 'pearson_correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KorSTS Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>filename</th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>24</td>\n",
       "      <td>2.5</td>\n",
       "      <td>한 소녀가 머리를 스타일링하고 있다.</td>\n",
       "      <td>한 소녀가 머리를 빗고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>33</td>\n",
       "      <td>3.6</td>\n",
       "      <td>한 무리의 남자들이 해변에서 축구를 한다.</td>\n",
       "      <td>한 무리의 소년들이 해변에서 축구를 하고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>한 여성이 다른 여성의 발목을 재고 있다.</td>\n",
       "      <td>한 여자는 다른 여자의 발목을 측정한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>63</td>\n",
       "      <td>4.2</td>\n",
       "      <td>한 남자가 오이를 자르고 있다.</td>\n",
       "      <td>한 남자가 오이를 자르고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>66</td>\n",
       "      <td>1.5</td>\n",
       "      <td>한 남자가 하프를 연주하고 있다.</td>\n",
       "      <td>한 남자가 키보드를 연주하고 있다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           genre filename      year  id  score                sentence1  \\\n",
       "0  main-captions   MSRvid  2012test  24    2.5     한 소녀가 머리를 스타일링하고 있다.   \n",
       "1  main-captions   MSRvid  2012test  33    3.6  한 무리의 남자들이 해변에서 축구를 한다.   \n",
       "2  main-captions   MSRvid  2012test  45    5.0  한 여성이 다른 여성의 발목을 재고 있다.   \n",
       "3  main-captions   MSRvid  2012test  63    4.2        한 남자가 오이를 자르고 있다.   \n",
       "4  main-captions   MSRvid  2012test  66    1.5       한 남자가 하프를 연주하고 있다.   \n",
       "\n",
       "                    sentence2  \n",
       "0            한 소녀가 머리를 빗고 있다.  \n",
       "1  한 무리의 소년들이 해변에서 축구를 하고 있다.  \n",
       "2      한 여자는 다른 여자의 발목을 측정한다.  \n",
       "3           한 남자가 오이를 자르고 있다.  \n",
       "4         한 남자가 키보드를 연주하고 있다.  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Test dataset\n",
    "TEST_STS_DF = os.path.join(DATA_IN_PATH, 'KorSTS', 'sts-test.tsv')\n",
    "\n",
    "test_data = pd.read_csv(TEST_STS_DF, header=0, delimiter = '\\t', quoting = 3)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jikim\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2149: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test set도 똑같은 방법으로 구성한다.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "data_labels = []\n",
    "\n",
    "for sent1, sent2, score in test_data[['sentence1', 'sentence2', 'score']].values:\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer_v2(clean_text(sent1), clean_text(sent2), MAX_LEN)\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(score)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(sent1, sent2)\n",
    "        pass\n",
    "    \n",
    "test_input_ids = np.array(input_ids, dtype=int)\n",
    "test_attention_masks = np.array(attention_masks, dtype=int)\n",
    "test_type_ids = np.array(token_type_ids, dtype=int)\n",
    "test_inputs = (test_input_ids, test_attention_masks, test_type_ids)\n",
    "test_data_labels = np.array(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 1379, # labels: 1379\n"
     ]
    }
   ],
   "source": [
    "print(\"# sents: {}, # labels: {}\".format(len(test_input_ids), len(test_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 424ms/step - loss: 1.0327 - pearson_correlation: 0.7615\n",
      "test loss, test pearson correlation:  [1.0327004194259644, 0.7614523768424988]\n"
     ]
    }
   ],
   "source": [
    "# regression_model.load_weights(checkpoint_path)\n",
    "tf.keras.utils.plot_model(regression_model, show_shapes=True, dpi=48)\n",
    "\n",
    "results = regression_model.evaluate(test_inputs, test_data_labels, batch_size=512)\n",
    "print(\"test loss, test pearson correlation: \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[  101,  9954, 76854, 11287,  9952, 28396, 11513,  9568, 16323,\n",
      "        12453, 11506,   102,  9102, 76854, 11287,  9952, 28396, 11513,\n",
      "         9568, 16323, 12453, 11506,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]]), array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))\n",
      "<class 'numpy.ndarray'>\n",
      "[[3.848838]]\n"
     ]
    }
   ],
   "source": [
    "sent1 = '한 남자가 하프를 연주하고 있다.'\n",
    "sent2 = '두 남자가 하프를 연주하고 있다.'\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "\n",
    "input_id, attention_mask, token_type_id = bert_tokenizer_v2(clean_text(sent1), clean_text(sent2), MAX_LEN)\n",
    "\n",
    "input_ids.append(input_id)\n",
    "attention_masks.append(attention_mask)\n",
    "token_type_ids.append(token_type_id)\n",
    "\n",
    "#test_inputs = (input_id, attention_mask, token_type_id)\n",
    "test_input_id = np.array(input_ids, dtype=int)\n",
    "test_attention_mask = np.array(attention_masks, dtype=int)\n",
    "test_type_id = np.array(token_type_ids, dtype=int)\n",
    "test_inputs = (test_input_id, test_attention_mask, test_type_id)\n",
    "# test_inputs = (test_input_id,)\n",
    "print(test_inputs)\n",
    "# test_inputs = (test_input_ids, test_attention_masks, test_type_ids)\n",
    "# test_data_labels = np.array(data_labels)\n",
    "result = regression_model.predict(test_inputs)\n",
    "\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
